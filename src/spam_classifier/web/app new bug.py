import streamlit as st
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import (
    confusion_matrix, roc_curve, auc, precision_recall_curve,
    f1_score, precision_score, recall_score, roc_auc_score
)
from collections import Counter

# -------- Utility Functions --------

@st.cache_data(show_spinner=False)
def load_data(path: str) -> pd.DataFrame:
    try:
        df = pd.read_csv(path)
        return df
    except Exception as e:
        st.error(f"Error loading data: {e}")
        return pd.DataFrame()

def infer_cols(df: pd.DataFrame):
    label = next((c for c in df.columns if 'label' in c.lower() or 'target' in c.lower()), df.columns[0])
    text = next((c for c in df.columns if 'text' in c.lower() or 'message' in c.lower()), df.columns[-1])
    return label, text

def token_topn(series: pd.Series, topn: int =20) -> pd.DataFrame:
    counter = Counter(" ".join(series.astype(str)).split())
    return pd.DataFrame(counter.most_common(topn), columns=['token', 'count'])

def available_models():
    return {
        "Logistic Regression": LogisticRegression(max_iter=1000),
        "Naive Bayes": MultinomialNB(),
        "Random Forest": RandomForestClassifier(),
        "SVM": SVC(probability=True)
    }

# -------- Classification Function --------

def classify_text(text, model, vectorizer, threshold):
    xtest = vectorizer.transform([text])
    proba = model.predict_proba(xtest)[0][1]
    pred = "Spam" if proba > threshold else "Ham"
    return pred, proba

# -------- Main App --------

def main():
    st.set_page_config(page_title="Spam Classifier Professional", layout="wide")
    st.title("ğŸ“§ AI Spam/Ham éƒµä»¶åˆ†é¡ç³»çµ±ï¼ˆæ¨¡çµ„åŒ–å°ˆæ¥­ç‰ˆï¼‰")
    st.caption("è³‡æ–™è·¯å¾‘ example: datasets/processed/sms_spam_clean.csv")

    # Sidebar controls
    with st.sidebar:
        st.header("è³‡æ–™èˆ‡æ¨¡å‹é¸æ“‡")
        data_path = st.text_input("è³‡æ–™é›†è·¯å¾‘", "datasets/processed/sms_spam_clean.csv")
        df = load_data(data_path)
        if not df.empty:
            label_col, text_col = infer_cols(df)
            st.info(f"Auto label col: `{label_col}` / text col: `{text_col}`")
            model_name = st.selectbox("æ¨¡å‹", list(available_models().keys()))
            test_size = st.slider("æ¸¬è©¦é›†æ¯”ä¾‹", 0.1, 0.4, 0.2, 0.01)
            threshold = st.slider("Spam é–¾å€¼", 0.1, 0.9, 0.5, 0.01)
            random_seed = st.number_input("éš¨æ©Ÿç¨®å­", value=42, step=1)
        else:
            label_col, text_col = "",""
            st.warning("No data loaded.")

    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ” åˆ†é¡é«”é©—", "ğŸ“Š è³‡æ–™èˆ‡è©é »", "ğŸ§ª æ€§èƒ½æ¯”è¼ƒ", "ğŸ“œ æ­·å²ç´€éŒ„"])

    # --- Classification Demo Tab ---
    with tab1:
        st.subheader("å³æ™‚éƒµä»¶ Spam/Ham åˆ†é¡")
        user_input = st.text_area("è«‹è¼¸å…¥éƒµä»¶å…§å®¹", height=150)
        run_pred = st.button("é€²è¡Œåˆ†é¡")
        if run_pred:
            if not user_input.strip():
                st.error("è«‹è¼¸å…¥éƒµä»¶å…§å®¹ã€‚")
            elif df.empty or label_col == "" or text_col == "":
                st.error("æœªè¼‰å…¥è³‡æ–™ã€‚")
            else:
                try:
                    X = df[text_col]
                    y = (df[label_col].astype(str).str.lower()=="spam").astype(int)
                    tfidf = TfidfVectorizer()
                    X_vec = tfidf.fit_transform(X)
                    model = available_models()[model_name]
                    model.fit(X_vec, y)
                    pred, proba = classify_text(user_input, model, tfidf, threshold)
                    st.metric("é æ¸¬çµæœ", pred, f"Spam æ©Ÿç‡ï¼š{proba:.3f} (é–¾å€¼ {threshold})")
                    st.write({"æ©Ÿç‡(Ham)": round(1-proba,3), "æ©Ÿç‡(Spam)": round(proba,3)})
                    # Save to history
                    if "history" not in st.session_state:
                        st.session_state["history"] = []
                    st.session_state["history"].append({
                        "input": user_input,
                        "prediction": pred,
                        "probability_spam": proba,
                        "timestamp": pd.Timestamp.now()
                    })
                except Exception as e:
                    st.error(f"Prediction error: {str(e)}")

    # --- Data Analysis Tab ---
    with tab2:
        st.subheader("è³‡æ–™ç‹€æ…‹")
        if not df.empty:
            st.write(df.head())
            st.write("æ¨™ç±¤åˆ†ä½ˆ")
            st.bar_chart(df[label_col].value_counts())
            st.write("è¨Šæ¯é•·åº¦åˆ†å¸ƒ")
            st.bar_chart(df[text_col].apply(len))
            st.write("é«˜é »è© (Ham)")
            st.table(token_topn(df[df[label_col].astype(str).str.lower()=="ham"][text_col], 20))
            st.write("é«˜é »è© (Spam)")
            st.table(token_topn(df[df[label_col].astype(str).str.lower()=="spam"][text_col], 20))

    # --- Model Performance Tab ---
    with tab3:
        st.subheader("å¤šæ¨¡å‹æ€§èƒ½å°æ¯”")
        if not df.empty:
            try:
                X = df[text_col]
                y = (df[label_col].astype(str).str.lower()=="spam").astype(int)
                Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=test_size, random_state=random_seed, stratify=y)
                tfidf = TfidfVectorizer()
                Xtrv = tfidf.fit_transform(Xtr)
                Xtev = tfidf.transform(Xte)
                perf = []
                for name, clf in available_models().items():
                    clf.fit(Xtrv, ytr)
                    probas = clf.predict_proba(Xtev)[:, 1]
                    ypred = (probas > threshold).astype(int)
                    metrics = {
                        "Model": name,
                        "Precision": precision_score(yte, ypred),
                        "Recall": recall_score(yte, ypred),
                        "F1": f1_score(yte, ypred),
                        "AUC": roc_auc_score(yte, probas)
                    }
                    perf.append(metrics)
                st.write(pd.DataFrame(perf).set_index("Model"))
                # Confusion Matrix & Curves
                chosen_model = available_models()[model_name]
                chosen_model.fit(Xtrv, ytr)
                cprob = chosen_model.predict_proba(Xtev)[:, 1]
                ypredc = (cprob > threshold).astype(int)
                cm = confusion_matrix(yte, ypredc)
                st.write("Confusion Matrix", pd.DataFrame(cm, index=["Ham", "Spam"], columns=["Pred Ham", "Pred Spam"]))
                fpr, tpr, _ = roc_curve(yte, cprob)
                precs, recs, _ = precision_recall_curve(yte, cprob)
                st.line_chart({"FPR":fpr, "TPR":tpr})
                st.line_chart({"Recall":recs, "Precision":precs})
            except Exception as e:
                st.error(f"æ€§èƒ½æ¯”è¼ƒéŒ¯èª¤: {str(e)}")

    # --- History Tab ---
    with tab4:
        st.subheader("åˆ†é¡æ­·å²ç´€éŒ„")
        history = st.session_state.get("history", [])
        if history:
            st.table(pd.DataFrame(history))
        else:
            st.write("ç›®å‰å°šç„¡åˆ†é¡ç´€éŒ„ã€‚")

if __name__ == "__main__":
    main()
